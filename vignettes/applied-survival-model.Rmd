---
title: "Applied Survival Models"
author: "Jacqueline Buros Novik"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Applied survival models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, eval = T, results = 'hide', echo = F}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.width = 11,
                      fig.height = 6
                      )
```


```{r load-packages, eval = T, echo = F}
library(httr)
library(readr)
library(cgdsr)
library(purrr)
library(dplyr)
library(assertthat)
library(ggplot2)
library(survival)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = min(4, parallel::detectCores()))
library(shinystan)
library(gridExtra)
library(ggfortify)
library(scales)
```

Survival modeling is a core component of any clinical data analysis toolset.

Right-censoring is by far the most common scenario, since patients cannot be followed indefinitely. There is also valuable information in the distribution of times to events, even in cases where all patients experience an outcome.

Fitting survival models in Stan is fairly straightforward. In this section, we will describe the model, fit the model to simulated data, and illustrate with an applied example.

The last part of this vignette includes some suggestions of ways to extend the standard Cox Proportional Hazards model. We will get to these if time allows.

# Background

In a survival modeling context, the dependent variable of interest is typically *time to event*. 

We will start by considering a single source of failure (death) vs censored observations.

We start with a parametric model, then implement a non-parametric fit.

# Data

We will illustrate this analysis using data from [The Cancer Genoma Atlas (TCGA)](https://tcga-data.nci.nih.gov) for patients diagnosed with Bladder Urothelial Carcinoma.

The complete clinical & molecular data are available from TCGA data portals, but in this case we will use a curated version of these data available from <http://www.cbioportal.org/>.

We *could* query these data via the web-url service: 

```{r example-load-data, eval = FALSE}
url <- 'http://www.cbioportal.org/webservice.do?cmd=getClinicalData&case_set_id=blca_tcga_all'
req <- httr::GET(url)
clinical_data <- 
    httr::content(req,
                  type = 'text/tab-separated-values',
                  col_names = T,
                  col_types = NULL
                  )
str(clinical_data)
```

However, MSKCC has provided the [CGDS-R](http://cran.r-project.org/web/packages/cgdsr/index.html) package, which provides an easier interface to the same data.

```{r actual-load-data}
mycgds = cgdsr::CGDS("http://www.cbioportal.org/public-portal/")
selected_case_list = 'blca_tcga_all'
clinical_data = cgdsr::getClinicalData(mycgds, selected_case_list)
```

List of fields available:

```{r inspect-data}
str(clinical_data,  no.list = T, vec.len = 2)
```

Let's do some minimal data manipulation on these data before going any further. We will save the converted data in a data.frame called `clin_data`.

```{r initprep-data}
## names to lower case
names(clinical_data) <- tolower(names(clinical_data))

## convert empty strings -> NA values
convert_blank_to_na <- function(x) {
    if (!purrr::is_character(x)) {
        warning('input vector is not character - returning original input')
        return(x)
    } else {
        ifelse(x == '', NA, x)
    }
}
clin_data <- clinical_data %>%
    dplyr::mutate_each(funs = funs(convert_blank_to_na), everything())

## inspect resulting data frame
str(clin_data, vec.len = 2, list.len = 10)
```

# First analysis: overall survival using parametric survival model

Our first pass at this analysis will treat mortality as the primary endpoint. We will fit the data using a parametric model which assumes that failure times are distributed according to a weibull distribution.

## Data prep

The relevant data are contained within two variables: `os_status` & `os_months`. 

For various reasons, these data include one observation with missing data for Overall Survival

```{r inspect-os-status}
clinical_data %>%
    dplyr::filter(is.na(os_status) | os_status == '') %>%
    dplyr::select(os_status, os_months) %>%
    str()
```

In addition, we have a 3 observations with unknown and/or negative survival times (`os_months < 0`).

```{r inspect-os-months}
clinical_data %>%
    dplyr::filter(!is.na(os_status) & os_status != '') %>%
    dplyr::filter(os_months < 0 | is.na(os_months)) %>%
    dplyr::select(os_status, os_months) %>%
    head()
```

For now, remove these observations from our analysis dataset (`clin_data`).

```{r create-clin-data}
clin_data <- 
    clin_data %>%
    dplyr::filter(!is.na(os_status) & os_status != '') %>%
    dplyr::filter(os_months >= 0 & !is.na(os_months))

## confirm 4 fewer observations than original
assert_that(nrow(clin_data) == nrow(clinical_data) - 4)
```

## Data exploration

We will do some minimal data exploration before attempting to fit the model.

Numerical summary of event times by event type

```{r summary-os-months}
clin_data %>%
    split(.$os_status) %>%
    purrr::map(~ summary(.$os_months))
```

Graphical summary of event times by type

```{r plot-os-months}
ggplot(clin_data,
       aes(x = os_months,
           group = os_status,
           colour = os_status,
           fill = os_status
           )) + 
    geom_density(alpha = 0.5)
```

Summarize MLE estimate of the survival function for these data and plot the KM survival curve for observed data. 

These will give us a benchmark for future evaluations.

```{r mle-survfit}
mle.surv <- 
    survfit(
        Surv(os_months,os_deceased) ~ 1,
        data = clin_data %>%
            dplyr::mutate(os_deceased = os_status == 'DECEASED')
    )
plot(mle.surv)
```


## Prepare data input for stan 

In order to call Stan, we must prepare a data input object
which will be passed to the compiled stan program. 
This input can be a `list` or an `environment` (since environments are implemented as lists). I prefer to 
work with lists directly.

The structure and type of elements in this `list` must match the components of the `data { ... }` block in our Stan code.

#### Write the input data list

Here we prepare the `list` object which we will pass to Stan

```{r stan-input-data}
observed_data <- clin_data %>%
    dplyr::filter(os_status == 'DECEASED')

censored_data <- clin_data %>%
    dplyr::filter(os_status != 'DECEASED')

stan_data <- list(
    Nobs = nrow(observed_data),
    Ncen = nrow(censored_data),
    M_bg = 1,
    yobs = observed_data$os_months,
    ycen = censored_data$os_months,
    Xobs_bg = array(rep_len(0, nrow(observed_data)), dim = c(nrow(observed_data), 1)),
    Xcen_bg = array(rep_len(0, nrow(censored_data)), dim = c(nrow(censored_data), 1))
)
str(stan_data)
```

## Setting initial values

## Fitting the model

We are now ready to try fitting the model to our data. 

### Test the model 

Personally, I test the code on a few iterations to confirm that my starting values are reasonable & that there are no problems executing the model code on the input data.

I find it's best to test on a handful of iterations & on a single chain. This makes debugging easier.

```{r stan-test-fit}
test_fit <- 
    rstan::stan(model_code = stan_code,
                data = stan_data,
                iter = 5,
                chains = 1,
                init = make_inits(1, 1))
```

Note that it's not surprising for us to have a fair number of implausible parameter values at this point. We are only a few iterations in. 

#### aside on input data types

Aside: for an example of how sensitive `stan()` is to dimension of inputs, try running the following exercize.

Compare the value of *a vector wrapped by `array()`*

```{r stan-alt-inits1a}
array(rnorm(0), dim = c(0))
```

with that of *a naked vector*

```{r stan-alt-inits2a}
rnorm(0)
```

These two look the same, don't they?

**However, looks can be deceiving. **

The data type stan is looking for is a `vector`: 

```{r review-stan-params}
for (l in 
     readLines(textConnection(
         gsub(stan_code,
              pattern = '.*(parameters \\{.*?\\}).*',
              replacement = '\\1'
              )
         ))
     )
    cat(l, '\n')
```

Ironically, the only way to force an R object to be a vector is to wrap it in the `array()` operator.

For example, compare the structure of *a vector wrapped in an array* 

```{r stan-alt-inits1b}
str(array(rnorm(0), dim = c(0)))
```

with the structure of *a naked vector*

```{r stan-alt-inits2b}
str(rnorm(0))
```

These are different objects in the eyes of `stan`. 

#### input data types in practice 

Notice what happens if we modify the `init` function to remove one of the `array()` wrappers listed above.

```{r alt-inits}
## alternate make-inits function for illustrative purposes
alt_make_inits <- function(M_bg, M_biom) {
    function()
      list(
        tau_s_bg_raw = 0.1*abs(rnorm(1)),
        tau_bg_raw = abs(rnorm(M_bg)),  ### removed array() wrapper
        tau_s1_biom_raw = 0.1*abs(rnorm(1)),
        tau_s2_biom_raw = 0.1*abs(rnorm(1)),
        tau_biom_raw = array(abs(rnorm(M_biom)), dim = c(M_biom)),
        tau1_biom_raw = abs(rnorm(M_biom)),
        tau2_biom_raw = abs(rnorm(M_biom)),
        alpha_raw = 0.01*rnorm(1),
        beta_bg_raw = array(rnorm(M_bg), dim = c(M_bg)),
        beta_biom_raw = array(rnorm(M_biom), dim = c(M_biom)),
        mu = rnorm(1)
      )
}
test_fit2 <- rstan::stan(model_code = stan_code, data = stan_data, iter = 10, chains = 1, init = alt_make_inits(1, 1))

```

... something to watch out for when passing data to stan.

## back to fitting model in stan

OK. With that covered, let's get back to fitting our model.

Next we try running this for more iterations and on multiple chains. 

*NB: here we reference the earlier fitted object instead of passing in the model code directly*

```{r stan-actual-fit}
wei_fit <- rstan::stan(fit = test_fit,
                       data = stan_data,
                       iter = 1000,
                       chains = 4,
                       init = make_inits(1, 1))
print(wei_fit)
```

## Checking convergence

Convergence can be assessed in various ways.

### Review Rhat values 

For a quick indication, we can look at the Rhat values (Gelman-Rubin convergence diagnostic) in the summary table above.

This is a useful gut-check, in that R-hat values far from 1 are a strong indication of a lack of convergence. Often the fix is as simple as running more iterations, or using a longer warmup sampling period.

An R-hat value close to one, however, does not have high sensitivity. It does not guarantee convergence.

### Inspect traceplots

We then also look at the traceplot of the log-posterior. I usually check this first since it gives me a sense of the overall model fit.

```{r lp-traceplot}
rstan::traceplot(wei_fit, c('lp__'), ncol = 1)
```

And, for key parameters (in this case, `alpha` & `mu`)

```{r param-traceplot}
rstan::traceplot(wei_fit, c('alpha','mu'), ncol = 1)
```

### Launch shinystan 

For more detailed model inspection we can leverage the awesome `shinystan`. 
This displays best-practice diagnostics (e.g. autocorrelation of chains) in an easy-to-use interface.

```{r launch-shinystan}
if (interactive())
    launch_shinystan(wei_fit)
```

## Posterior predictive checks

Now that we have a reasonable confidence that the model converged, we can ask how well the model fits our data. One way to interrogate a model is to *use it to simulate new data*, then see how similar those simulated values are to the real (observed) data.

These simulated datasets are often called **posterior predictions**. If you were to simulate your data for each draw from the posterior & average over those draws, you could estimate the **credible intervals of predicted values**. The distributions of predicted values are often called **posterior predictive distributions**. 

A question that is often asked when doing posterior predictive checks: 

1. Is my model well calibrated?
    - Are my observed data consistent with the model?
    - IE do my observed values fall within the 50% credible intervals 50% of the time?
2. Does my model recover key features of my data?
    - Is the distribution of the data similar to that simulated from the model?
    - Are the simulated values plausible? Is the choice of distributions appropriate?

We can additionally ask (in order to check our model code) whether the model can recover values from simulated data. 

### How to simulate draws from the posterior

In general, we can simulate draws from the posterior predictive distribution in R or in Stan. 

In Stan, you would do this using the "generated quantities" block. Under this scenario, Stan would generate the posterior predicted quantities for each draw from the posterior and include those values among the returned parameters.

For example, for this model, our generated quantities block might look like the following: 

```
generated quantities {
    int[Nobs] yhat_obs;
    int[Ncen] yhat_cen;
    
    for (n in 1:Nobs) {
        yhat_obs <- weibull_rng(alpha, exp(-(mu + Xobs_bg[n] * beta_bg)/alpha));
    }
    for (n in 1:Ncen) {
        yhat_cen <- uniform_rng(0, 1) * weibull_rng(alpha, exp(-(mu + Xobs_bg[n] * beta_bg)/alpha));
    }
}
```

In R, you would write a function to compute the predictive quantity of interest & compute that function either for the mean values of parameters over the posterior draws, or to each draw from the posterior. 

Since we are R users (this is an R conference!) we will do the latter. 

*NB: This scenario has the added benefit of allowing you to compute out-of-sample predictive values over the posterior densities of parameter estimates without having to call Stan again.*

** Process outline ** 

1. Write a function to simulate posterior predictive values given example parameter values.
2. Test code on example parameter value.
3. Apply function to each draw from the posterior estimates of the parameters.
4. Summarize survival at each time over draws from the posterior 

### Computing predicted values

The process for computing posterior predicted values starts with that used to simulate data.

Since in our case all covariate values are 0, only two parameters are relevant: `alpha` & `mu`.

It's also worth noting that we did not include anything in our model about the **censoring process**.  We are assuming that this process is not informative to our estimates of `beta`. We will therefore use a generic censoring process when simulating data, and take care to summarize our posterior predictions using a method invariant to the censoring process.

#### Function to simulate data

This function takes the two parameters (`alpha` & `mu`) and two sample sizes (`Nobs` & `Ncen`). It will return a data frame of simulated event/censor times. 

```{r sim-post-predict}

```

#### computing KM curve from simulated data

Next, we want 

```{r mean-post-predict}

## plot distribution of survival times by event type
ggplot(sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data))
       , aes(x = os_months, group = os_status, colour = os_status, fill = os_status)) +
    geom_density(alpha = 0.3)

```

How does this compare to the observed data?

```{r compare-mean-ppd}
ggplot(sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data)) %>%
           dplyr::mutate(type = 'posterior predicted values') %>%
           bind_rows(clin_data %>% dplyr::mutate(type = 'actual data'))
       , aes(x = os_months, group = os_status, colour = os_status, fill = os_status)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~type, ncol = 1)
```

Plotting as a survival curve

```{r compare-mean-ppdsurv}
sim_post_data <- sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data))
simppd.surv <- survival::survfit(Surv(os_months,os_deceased) ~ 1, data = sim_post_data %>% dplyr::mutate(os_deceased = os_status == 'DECEASED'))
simplot <- autoplot(simppd.surv) + ggtitle('Simulated data')
mleplot <- autoplot(mle.surv) + ggtitle('Actual data')
grid.arrange(simplot, mleplot, ncol = 2)
```

Overlaying observed & simulated survival curves (still using posterior mean of parameters)

```{r compare-mean-ppdsurv2, fig.width=11, fig.height=6}
ggplot(data = 
           fortify(simppd.surv) %>% 
           mutate(src = 'posterior predicted values') %>% 
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src))  +
    ggtitle('Survival curve for observed and posterior predicted event times \n (simulated according to mean of posterior parameter estimates)')
```

## Further posterior predictive checking

But, this is only an approximation to the true posterior predictive checks we want to do. The means of the parameter estimates don't reflect our true uncertainty in the parameter estimates.

To get to this point, we will want to repeat the above-described process *for each draw from the posterior*.

Let's do this now.

First let's review how to extract the parameters from the stanfit object.

```{r}
pp_mu <- extract(wei_fit, 'mu')$mu
str(pp_mu)
```

Why do we have 2000 values? 

(answer: 4 chains * 1000 iterations / 2 since by default warmup iters are dropped)

We should have a similar structure of values for `alpha`.

```{r}
pp_alpha <- extract(wei_fit, 'alpha')$alpha
str(pp_alpha)
```

To get the estimated variance in our survival curves, we will want to apply the same steps we did above (using the single point-estimate of the mean of alpha & mu) to each iteration.

Thanks to @hadley, we can do this using `purrr`.

```{r}
models <- 
    purrr::map2(pp_alpha,
                pp_mu,
                ~ sim_post_predict(alpha = .x,
                                   mu = .y,
                                   Nobs = nrow(observed_data),
                                   Ncen = nrow(censored_data))) %>%
    purrr::map(~ dplyr::mutate(., os_deceased = os_status == 'DECEASED')) %>%
    purrr::map(~ survival::survfit(Surv(os_months, os_deceased) ~ 1, data = .)) %>%
    purrr::map(fortify)
```

We should now have 2000 estimates of the survival curve, one for each post-warmup draw.

```{r}
class(models)
length(models)
head(models[[1]])
```

How to summarize the estimated uncertainty in our survival curve?

(A: For each observed time, we want to summarize the distribution of `surv` estimates)

Problem is, we don't observe the same timepoints for each iteration. One way to address this would be to aggregate the data for intervals of time.

```{r}
models_agg <- 
    models %>%
    purrr::map(~ dplyr::mutate(., time_group = floor(time))) %>%
    dplyr::bind_rows() %>%
    dplyr::group_by(time_group) %>%
    dplyr::summarize(surv_mean = mean(surv)
                     , surv_p50 = median(surv)
                     , surv_lower = quantile(surv, probs = 0.025)
                     , surv_upper = quantile(surv, probs = 0.975)
                     ) %>%
    dplyr::ungroup()

ggplot(models_agg, aes(x = time_group)) + geom_line(aes(y = surv_mean)) + geom_ribbon(aes(ymin = surv_lower, ymax = surv_upper), alpha = 0.2) + xlim(c(0, max(clin_data$os_months)))
```


Comparing posterior predicted intervals with observed data 

```{r}

ggplot(data = 
           models_agg %>% 
           dplyr::mutate(src = 'posterior predicted values (sampled)') %>% 
           dplyr::rename(time = time_group, surv = surv_mean, lower = surv_lower, upper = surv_upper) %>%
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = src), alpha = 0.2) +
    xlim(c(0, max(clin_data$os_months))) +
    ggtitle('Survival curve for observed and posterior predicted event times')


```
    

Comparing actual & approximate posterior estimates 

```{r}
ggplot(data = 
           models_agg %>% 
           dplyr::mutate(src = 'posterior predicted values (sampled)') %>% 
           dplyr::rename(time = time_group, surv = surv_mean, lower = surv_lower, upper = surv_upper) %>%
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')) %>%
           bind_rows(fortify(simppd.surv) %>% mutate(src = 'posterior predicted values (using mean)')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = src), alpha = 0.2) +
    xlim(c(0, max(clin_data$os_months))) +
    ggtitle('Survival curve for observed and posterior predicted event times') +
    theme_minimal()
```

