---
title: "Applied Survival Models"
author: "Jacqueline Buros Novik"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Applied survival models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Survival modeling is a core component of any clinical data analysis toolset.

Right-censoring is by far the most common scenario, since patients cannot be followed indefinitely. There is also valuable information in the distribution of times to events, even in cases where all patients experience an outcome.

Fitting survival models in Stan is fairly straightforward. In this section, we will describe the model, fit the model to simulated data, and illustrate with an applied example.

The last part of this vignette includes some suggestions of ways to extend the standard Cox Proportional Hazards model. We will get to these if time allows.

## Background

In a survival modeling context, the dependent variable of interest is typically *time to event*. 

We will start by considering a single source of failure (death) vs censored observations.

In general, there are parametric & non-parametric survival models. Here we will be 

## Data

We will illustrate this analysis using data from [The Cancer Genoma Atlas (TCGA)](https://tcga-data.nci.nih.gov) for patients diagnosed with Bladder Urothelial Carcinoma.

The complete clinical & molecular data are available from TCGA data portals, but in this case we will use a curated version of these data available from <http://www.cbioportal.org/>.

We *could* query these data via the web-url service: 

```{r, eval = FALSE}
library(httr)
library(readr)
url <- 'http://www.cbioportal.org/webservice.do?cmd=getClinicalData&case_set_id=blca_tcga_all'
req <- httr::GET(url)
clinical_data <- httr::content(req, type = 'text/tab-separated-values', col_names = T, col_types = NULL)
str(clinical_data)
```

However, MSKCC has provided the [CGDS-R](http://cran.r-project.org/web/packages/cgdsr/index.html) package, which makes this just as easy.

```{r}
library(cgdsr)
mycgds = cgdsr::CGDS("http://www.cbioportal.org/public-portal/")
selected_case_list = 'blca_tcga_all'
clinical_data = cgdsr::getClinicalData(mycgds, selected_case_list)
str(clinical_data)
```

Let's do some minimal data manipulation on these data before going any further. We will save the converted data in a data.frame called `clin_data`.

```{r}
library(purrr)
library(dplyr)

## names to lower case
names(clinical_data) <- tolower(names(clinical_data))

## convert empty strings -> NA values
convert_blank_to_na <- function(x) {
    if (!purrr::is_character(x)) {
        warning('input vector is not character - returning original input')
        return(x)
    } else {
        ifelse(x == '', NA, x)
    }
}
clin_data <- clinical_data %>%
    dplyr::mutate_each(funs = funs(convert_blank_to_na), everything())
str(clin_data)
```

## First pass: overall survival

Our first pass will treat mortality as the primary endpoint. 

### Data prep

The relevant data are contained within two variables: os_status & os_months. 

For various reasons, these data include one observation with missing data for Overall Survival

```{r}
clinical_data %>%
    dplyr::filter(is.na(os_status) | os_status == '') %>%
    str()
```

In addition, we have a 3 observations with unknown and/or negative survival times (`os_months` < 0).

```{r}
clinical_data %>%
    dplyr::filter(!is.na(os_status) & os_status != '') %>%
    dplyr::filter(os_months < 0 | is.na(os_months)) %>%
    dplyr::select(os_status, os_months) %>%
    head()
```

We will remove these observations from our analysis dataset (clin_data) for now.

```{r}
library(assertthat)
clin_data <- 
    clin_data %>%
    dplyr::filter(!is.na(os_status) & os_status != '') %>%
    dplyr::filter(os_months >= 0 & !is.na(os_months))

## at this point, we should have 4 fewer observations than our original dataset. Let's confirm this.
assert_that(nrow(clin_data) == nrow(clinical_data) - 4)
```

### Data exploration

We will do some minimal data exploration before attempting to fit the model.

Summarize distribution of event times by failure type

```{r}
clin_data %>%
    split(.$os_status) %>%
    purrr::map(~ summary(.$os_months))
```

And, graphically

```{r}
library(ggplot2)
ggplot(clin_data, aes(x = os_months, group = os_status, colour = os_status, fill = os_status)) + 
    geom_density(alpha = 0.5)
```

Let's look at the MLE estimate of the survival function for these data. This will give us a benchmark for future evaluations.

```{r}
library(survival)
mle.surv <- survfit(Surv(os_months,os_deceased) ~ 1, data = clin_data %>% dplyr::mutate(os_deceased = os_status == 'DECEASED'))
plot(mle.surv)
```

## A parametric survival model

For our first analysis we will implement a parametric survival model implemented by [Peltola et al (2014)](http://ceur-ws.org/Vol-1218/bmaw2014_paper_8.pdf). 

#### Stan code for the model

The Stan file for this model is adapted from their accompanying [github repo](https://github.com/to-mi/stan-survival-shrinkage).

```{r}
stan_code <- httr::content(httr::GET('https://raw.githubusercontent.com/to-mi/stan-survival-shrinkage/master/wei_gau.stan'), as = 'text')

for (l in readLines(textConnection(stan_code)))
    print(l)
```

#### Data inputs 

Next, we prep a data input object which we will pass to Stan. This is a `list` and the type of each element in the list should match the components of the `data { ... }` block in our stan code.

Let's review the data block again.

```{r}
for (l in readLines(textConnection(gsub(stan_code, pattern = '.*data \\{(.*?)\\}.*', replacement = "\\1")))) 
    print(l)
```

Notice how the censored & observed data points are separated.

In this case, we want to fit a NULL model but the stan code isn't written to accomodate the no-biomarker case. 

Thus, we will instead fill in biomarker values of 0.

```{r}
observed_data <- clin_data %>%
    dplyr::filter(os_status == 'DECEASED')

censored_data <- clin_data %>%
    dplyr::filter(os_status != 'DECEASED')

stan_data <- list(
    Nobs = nrow(observed_data),
    Ncen = nrow(censored_data),
    M_bg = 1,
    M_biom = 1,
    yobs = observed_data$os_months,
    ycen = censored_data$os_months,
    Xobs_bg = array(rep_len(0, nrow(observed_data)), dim = c(nrow(observed_data), 1)),
    Xcen_bg = array(rep_len(0, nrow(censored_data)), dim = c(nrow(censored_data), 1)),
    Xobs_biom = array(rep_len(0, nrow(observed_data)), dim = c(nrow(observed_data), 1)),
    Xcen_biom = array(rep_len(0, nrow(censored_data)), dim = c(nrow(censored_data), 1))
)
str(stan_data)
```

#### Initial values

Next, we wrap the [example.R](https://github.com/to-mi/stan-survival-shrinkage/blob/master/example.R#L88-L103) code in a function. 

This will generate the initial values for each parameter in our stan code. This is a function so that we can initialize each chain to a different set of starting values.

```{r}
make_inits <- function(M_bg, M_biom) {
    function()
      list(
        tau_s_bg_raw = 0.1*abs(rnorm(1)),
        tau_bg_raw = array(abs(rnorm(M_bg)), dim = c(M_bg)),
        tau_s1_biom_raw = 0.1*abs(rnorm(1)),
        tau_s2_biom_raw = 0.1*abs(rnorm(1)),
        tau_biom_raw = array(abs(rnorm(M_biom)), dim = c(M_biom)),
        tau1_biom_raw = abs(rnorm(M_biom)),
        tau2_biom_raw = abs(rnorm(M_biom)),
        alpha_raw = 0.01*rnorm(1),
        beta_bg_raw = array(rnorm(M_bg), dim = c(M_bg)),
        beta_biom_raw = array(rnorm(M_biom), dim = c(M_biom)),
        mu = rnorm(1)
      )
}
## example : 
str(make_inits(1, 1)())
```

#### Fitting the model

We are now ready to try fitting the model to our data. 

Personally, I test the code on a few iterations to confirm that my starting values are reasonable & that there are no problems executing the model code on the input data.

I find it's best to test on a handful of iterations & on a single chain. This makes debugging easier.

```{r}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = min(4, parallel::detectCores()))

test_fit <- rstan::stan(model_code = stan_code, data = stan_data, iter = 10, chains = 1, init = make_inits(1, 1))
```

Note that it's not surprising for us to have a fair number of implausible parameter values at this point. We are only a few iterations in. 

Next we try running this for more iterations and on multiple chains. 

*NB: here we reference the earlier fitted object instead of passing in the model code directly*

```{r}
wei_fit <- rstan::stan(fit = test_fit, data = stan_data, iter = 1000, chains = 4, init = make_inits(1, 1))
print(wei_fit)
```

#### Checking convergence

Convergence can be assessed in various ways.

For a quick indication, we can look at the Rhat values in the summary table above.

We then also look at the traceplot of the log-posterior 

```{r}
rstan::traceplot(wei_fit, c('lp__'), ncol = 1)
```

And, for key parameters (in this case, `alpha` & `mu`)

```{r}
rstan::traceplot(wei_fit, c('alpha','mu'), ncol = 1)
```

For more detailed model inspection we can leverage the awesome `shinystan`. 
This displays best-practice diagnostics (e.g. autocorrelation of chains) in an easy-to-use interface.

```{r}
library(shinystan)
if (interactive())
    launch_shinystan(wei_fit)
```

#### Posterior predictive checks

We can simulate draws from the posterior predictive distribution in R or in stan. 

Since the biomarker values given weren't informative, we only want to inspect the baseline hazard or survival functions.

The only two parameters needed to specify these are `alpha` & `mu`.

```{r}
sim_post_predict <- function(alpha, mu, Nobs, Ncen) {
    observed_data <- data.frame(os_status = rep_len('DECEASED', Nobs),
                                os_months = rweibull(n = Nobs, alpha, exp(-(mu)/alpha)),
                                stringsAsFactors = F
                                )
    
    censored_data <- data.frame(os_status = rep_len('LIVING', Ncen),
                                os_months = runif(n = Ncen) * rweibull(Ncen, alpha, exp(-(mu)/alpha)),
                                stringsAsFactors = F
                                )
    
    return(observed_data %>% bind_rows(censored_data))
}

## test these inputs for arbitrary values of alpha & mu
sim_post_predict(alpha = 0.9, mu = -3.76, Nobs = nrow(observed_data), Ncen = nrow(censored_data)) %>%
    head()
```

Let's plot the mean time to survival in our simulated data, using the posterior means

```{r}

mean_estimated_mu <- mean(rstan::extract(wei_fit, 'mu')$mu)
mean_estimated_alpha <- mean(rstan::extract(wei_fit, 'alpha')$alpha)

## plot distribution of survival times by event type
ggplot(sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data))
       , aes(x = os_months, group = os_status, colour = os_status, fill = os_status)) +
    geom_density(alpha = 0.3)

```

How does this compare to the observed data?

```{r}
ggplot(sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data)) %>%
           dplyr::mutate(type = 'posterior predicted values') %>%
           bind_rows(clin_data %>% dplyr::mutate(type = 'actual data'))
       , aes(x = os_months, group = os_status, colour = os_status, fill = os_status)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~type, ncol = 1)
```

Plotting as a survival curve

```{r}
library(gridExtra)
library(ggfortify)
sim_post_data <- sim_post_predict(alpha = mean_estimated_alpha, mu = mean_estimated_mu, Nobs = nrow(observed_data), Ncen = nrow(censored_data))
simppd.surv <- survival::survfit(Surv(os_months,os_deceased) ~ 1, data = sim_post_data %>% dplyr::mutate(os_deceased = os_status == 'DECEASED'))
simplot <- autoplot(simppd.surv) + ggtitle('Simulated data')
mleplot <- autoplot(mle.surv) + ggtitle('Actual data')
grid.arrange(simplot, mleplot, ncol = 2)
```

Overlaying observed & simulated survival curves (still using posterior mean of parameters)

```{r}
ggplot(data = 
           fortify(simppd.surv) %>% 
           mutate(src = 'posterior predicted values') %>% 
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = src), alpha = 0.2) +
    ggtitle('Survival curve for observed and posterior predicted event times \n (simulated according to mean of posterior parameter estimates)')
```

#### Further posterior predictive checking

But, this is only an approximation to the true posterior predictive checks we want to do. The means of the parameter estimates don't reflect our true uncertainty in the parameter estimates.

To get to this point, we will want to repeat the above-described process *for each draw from the posterior*.

Let's do this now.

First let's review how to extract the parameters from the stanfit object.

```{r}
pp_mu <- extract(wei_fit, 'mu')$mu
str(pp_mu)
```

Why do we have 2000 values? 

(answer: 4 chains * 1000 iterations / 2 since by default warmup iters are dropped)

We should have a similar structure of values for `alpha`.

```{r}
pp_alpha <- extract(wei_fit, 'alpha')$alpha
str(pp_alpha)
```

To get the estimated variance in our survival curves, we will want to apply the same steps we did above (using the single point-estimate of the mean of alpha & mu) to each iteration.

Thanks to @hadley, we can do this using `purrr`.

```{r}
models <- 
    purrr::map2(pp_alpha, pp_mu, ~ sim_post_predict(alpha = .x, mu = .y, Nobs = nrow(observed_data), Ncen = nrow(censored_data))) %>%
    purrr::map(~ dplyr::mutate(., os_deceased = os_status == 'DECEASED')) %>%
    purrr::map(~ survival::survfit(Surv(os_months, os_deceased) ~ 1, data = .)) %>%
    purrr::map(fortify)
```

We should now have 2000 estimates of the survival curve, one for each post-warmup draw.

```{r}
class(models)
length(models)
head(models[[1]])
```

How to summarize the estimated uncertainty in our survival curve?

(A: For each observed time, we want to summarize the distribution of `surv` estimates)

Problem is, we don't observe the same timepoints for each iteration. One way to address this would be to aggregate the data for intervals of time.

```{r}
models_agg <- 
    models %>%
    purrr::map(~ dplyr::mutate(., time_group = floor(time))) %>%
    dplyr::bind_rows() %>%
    dplyr::group_by(time_group) %>%
    dplyr::summarize(surv_mean = mean(surv)
                     , surv_p50 = median(surv)
                     , surv_lower = quantile(surv, probs = 0.025)
                     , surv_upper = quantile(surv, probs = 0.975)
                     ) %>%
    dplyr::ungroup()

ggplot(models_agg, aes(x = time_group)) + geom_line(aes(y = surv_mean)) + geom_ribbon(aes(ymin = surv_lower, ymax = surv_upper), alpha = 0.2) + xlim(c(0, max(clin_data$os_months)))
```


Comparing posterior predicted intervals with observed data 

```{r}

ggplot(data = 
           models_agg %>% 
           dplyr::mutate(src = 'posterior predicted values (sampled)') %>% 
           dplyr::rename(time = time_group, surv = surv_mean, lower = surv_lower, upper = surv_upper) %>%
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = src), alpha = 0.2) +
    xlim(c(0, max(clin_data$os_months))) +
    ggtitle('Survival curve for observed and posterior predicted event times')


```
    

Comparing actual & approximate posterior estimates 

```{r}
ggplot(data = 
           models_agg %>% 
           dplyr::mutate(src = 'posterior predicted values (sampled)') %>% 
           dplyr::rename(time = time_group, surv = surv_mean, lower = surv_lower, upper = surv_upper) %>%
           bind_rows(fortify(mle.surv) %>% mutate(src = 'actual data')) %>%
           bind_rows(fortify(simppd.surv) %>% mutate(src = 'posterior predicted values (using mean)')),
       aes(x = time, group = src)) + 
    geom_line(aes(y = surv, colour = src)) + 
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = src), alpha = 0.2) +
    xlim(c(0, max(clin_data$os_months))) +
    ggtitle('Survival curve for observed and posterior predicted event times')
```


What if we computed this a different way?  IE pooling together all posterior predicted event times into one big data set.

Would this be a more correct summary than the above? 

```{r}
ppd_data <- 
    purrr::map2(pp_alpha, pp_mu, ~ sim_post_predict(alpha = .x, mu = .y, Nobs = nrow(observed_data), Ncen = nrow(censored_data))) %>%
    purrr::map(~ dplyr::mutate(., os_deceased = os_status == 'DECEASED')) %>%
    dplyr::bind_rows()

simppd2.surv <- survival::survfit(Surv(os_months, os_deceased) ~ 1, data = ppd_data)

## not run due to processing constraints: 
## autoplot(simppd2.surv)
```

